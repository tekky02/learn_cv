{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGANS_torch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1462cpMK2Z_AnyaNwAY9iPCxkst_mqjkG",
      "authorship_tag": "ABX9TyMVWRHFU/ACNEkaeV/R6Ztq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tekky02/learn_cv/blob/master/DCGANS_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4gWM2UEiXtU"
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvsWxGiui03R",
        "outputId": "e6af47c5-b8b4-4644-8aa2-6e5a3feb4a7d"
      },
      "source": [
        "# 获取数据\n",
        "!pip install pyunpack\n",
        "!pip install patool\n",
        "from pyunpack import Archive\n",
        "\n",
        "IMAGE_PATH = \"drive/MyDrive/Colab Notebooks/faces.7z\"\n",
        "\n",
        "Archive(IMAGE_PATH).extractall(\".\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/b0/8ef4b1d8be02448d164c52466530059d7f57218655d21309a0c4236d7454/entrypoint2-0.2.4-py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed easyprocess-0.3 entrypoint2-0.2.4 pyunpack-0.2.2\n",
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.6MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT2oJLpjjTRv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG140_r6K5Ae"
      },
      "source": [
        "def get_imgs(path):\n",
        "  files = os.listdir(path)\n",
        "  imgs = []\n",
        "  for file in files:\n",
        "    # imgs.append(cv2.imread(os.path.join(path, file))[:,:,::-1])\n",
        "    imgs.append(cv2.imread(os.path.join(path, file)))\n",
        "\n",
        "  return imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y84Z3hH6Qpvd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.init as init\n",
        "from torchvision import transforms\n",
        " \n",
        "trans = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
        "    ]\n",
        ")\n",
        " \n",
        "def init_ws_bs(m):\n",
        "    if isinstance(m, nn.ConvTranspose2d):\n",
        "        init.normal_(m.weight.data, std=0.2)\n",
        "        init.normal_(m.bias.data, std=0.2)\n",
        " \n",
        " \n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
        "                in_channels=100,\n",
        "                out_channels=64 * 8,\n",
        "                kernel_size=4,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(64 * 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
        "                in_channels=64 * 8,\n",
        "                out_channels=64 * 4,\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(64 * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
        "                in_channels=64 * 4,\n",
        "                out_channels=64 * 2,\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(  # stride(input_w-1)+k-2*Padding\n",
        "                in_channels=64 * 2,\n",
        "                out_channels=64 * 1,\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.deconv5 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 3, 5, 3, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.deconv4(x)\n",
        "        x = self.deconv5(x)\n",
        "        return x\n",
        " \n",
        " \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(  # batchsize,3,96,96\n",
        "                in_channels=3,\n",
        "                out_channels=64,\n",
        "                kernel_size=5,\n",
        "                padding=1,\n",
        "                stride=3,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(.2, inplace=True),\n",
        " \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False, ),  # batchsize,16,32,32\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.LeakyReLU(.2, inplace=True),\n",
        " \n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 4),\n",
        "            nn.LeakyReLU(.2, inplace=True),\n",
        " \n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 8),\n",
        "            nn.LeakyReLU(.2, inplace=True),\n",
        " \n",
        "        )\n",
        "        self.output = nn.Sequential(\n",
        "            nn.Conv2d(64 * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()  #\n",
        "        )\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.output(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS2afSzSlVtn"
      },
      "source": [
        "创建模型\n",
        "\n",
        "配置损失函数和优化器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9kLU57xlSpg"
      },
      "source": [
        "G_LR = 0.0002\n",
        "D_LR = 0.0002\n",
        "BATCHSIZE = 50\n",
        "EPOCHES = 3000\n",
        "\n",
        "g = Generator().cuda()\n",
        "d = Discriminator().cuda()\n",
        " \n",
        "init_ws_bs(g), init_ws_bs(d)\n",
        " \n",
        "g_optimizer = torch.optim.Adam(g.parameters(), betas=(.5, 0.999), lr=G_LR)\n",
        "d_optimizer = torch.optim.Adam(d.parameters(), betas=(.5, 0.999), lr=D_LR)\n",
        " \n",
        "g_loss_func = nn.BCELoss()\n",
        "d_loss_func = nn.BCELoss()\n",
        " \n",
        "label_real = torch.ones(BATCHSIZE).cuda()\n",
        "label_fake = torch.zeros(BATCHSIZE).cuda()\n",
        " \n",
        "real_img = get_imgs(\"faces\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6E-dHFzoMYA"
      },
      "source": [
        "os.mkdir(\"pkl\")\n",
        "os.mkdir(\"result\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEcFUb9KlgSJ"
      },
      "source": [
        "for epoch in range(EPOCHES):\n",
        "    np.random.shuffle(real_img)\n",
        "    count = 0\n",
        "    batch_imgs = []\n",
        "    for i in range(len(real_img)):\n",
        "        count = count + 1\n",
        "        batch_imgs.append(trans(real_img[i]).numpy())  # tensor类型#这里经过trans操作通道维度从第四个到第二个了\n",
        " \n",
        "        if count == BATCHSIZE:\n",
        "            count = 0\n",
        " \n",
        "            batch_real = torch.Tensor(batch_imgs).cuda()\n",
        "            batch_imgs.clear()\n",
        "            d_optimizer.zero_grad()\n",
        "            pre_real = d(batch_real).squeeze()\n",
        "            d_real_loss = d_loss_func(pre_real, label_real)\n",
        "            d_real_loss.backward()\n",
        " \n",
        "            batch_fake = torch.randn(BATCHSIZE, 100, 1, 1).cuda()\n",
        "            img_fake = g(batch_fake).detach()\n",
        "            pre_fake = d(img_fake).squeeze()\n",
        "            d_fake_loss = d_loss_func(pre_fake, label_fake)\n",
        "            d_fake_loss.backward()\n",
        " \n",
        "            d_optimizer.step()\n",
        " \n",
        "            g_optimizer.zero_grad()\n",
        "            batch_fake = torch.randn(BATCHSIZE, 100, 1, 1).cuda()\n",
        "            img_fake = g(batch_fake)\n",
        "            pre_fake = d(img_fake).squeeze()\n",
        "            g_loss = g_loss_func(pre_fake, label_real)\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        " \n",
        "            # print(i,(d_real_loss + d_fake_loss).detach().cpu().numpy(), g_loss.detach().cpu().numpy())\n",
        " \n",
        "            torch.save(g, \"pkl/\" + str(epoch) + \"g.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgHBFF-LkT22"
      },
      "source": [
        "# 使用训练好的模型生成图片\n",
        "gen = torch.load(\"pkl/19g.pkl\")\n",
        "imgs = gen(torch.randn(100, 100, 1, 1).cuda())\n",
        "\n",
        "for i in range(len(imgs)):\n",
        "  img = imgs[i].permute(1, 2, 0).cpu().detach().numpy()*255\n",
        "  cv2.imwrite(\"result/\"+str(i)+\".jpg\",img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlNX61UctLvC"
      },
      "source": [
        "from google.colab import files\n",
        "import os, tarfile\n",
        "\n",
        "def download_file(output_file, input_path):\n",
        "  tar = tarfile.open(output_file, 'w')\n",
        "  for file in os.listdir(input_path):\n",
        "    tar.add(os.path.join(input_path, file))\n",
        "\n",
        "  tar.close()\n",
        "\n",
        "  files.download(output_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NEI61qYtrHz2",
        "outputId": "cfe60d53-ab2c-4295-c630-6035c39936c9"
      },
      "source": [
        "# 下载生成的图像\n",
        "download_file('result.tar', 'result')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_962d2e57-a23c-4977-af74-603cd51fb99f\", \"result.tar\", 665600)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Y10_Vws5u5Fn",
        "outputId": "5bedfdc5-de92-4746-c664-f34dd6bf54f3"
      },
      "source": [
        "# 下载模型\n",
        "download_file('pkl.tar', 'pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c024fe7a-6a4b-4c5a-a5ba-02f8489e5cc9\", \"pkl.tar\", 286679040)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}